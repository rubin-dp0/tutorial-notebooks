{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src = https://project.lsst.org/sites/default/files/Rubin-O-Logo_0.png width=250, style=\"padding: 10px\"> \n",
    "<b>Interactive Image Visualization</b> <br>\n",
    "Last verified to run on <b>2021-06-25</b> with LSST Science Pipelines release <b>w_2021_25</b> <br>\n",
    "Contact authors: Leanne Guy <br>\n",
    "Credit: Originally developed by Keith Bechtol in the context of the Stack Club <br>\n",
    "Target audience: All DP0 delegates. <br>\n",
    "Container Size: medium <br>\n",
    "Questions welcome at <a href=\"https://community.lsst.org/c/support/dp0\">community.lsst.org/c/support/dp0</a> <br>\n",
    "Find DP0 documentation and resources at <a href=\"https://dp0-1.lsst.io\">dp0-1.lsst.io</a> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of Contents**\n",
    "1. Introduction to interactive visualization with Bokeh and Holoviews and Datashader <br>\n",
    "2. Interactive exposure image visualization<br>\n",
    "3. DP0.1 catalog data sample<br>\n",
    "4. Brushing and linking between scatter plots with Bokeh\n",
    "5. Further analysis with Holoviews linked streams\n",
    "6. Visualizing Larger Datasets with DatashaderÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General python imports\n",
    "import numpy as np\n",
    "\n",
    "# Astropy\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "# Bokeh and Holoviews for visualization\n",
    "import bokeh\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.models import ColumnDataSource, Range1d, HoverTool\n",
    "from bokeh.models import Selection, CDSView, GroupFilter\n",
    "from bokeh.plotting import figure, gridplot\n",
    "from bokeh.transform import factor_cmap\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import streams\n",
    "from holoviews.operation.datashader import datashade, dynspread, rasterize\n",
    "from holoviews.plotting.util import process_cmap\n",
    "import datashader as dsh\n",
    "\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Display bokeh plots inline in the notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Introduction <br>\n",
    "\n",
    "#### 1.1 Interactive Imge Visualization with Visualization with Bokeh, HoloViews<br>\n",
    "\n",
    "In the tutorial 03_Image_Display_and_Manipulation (afw) we saw how to use the `lsst.afw.display` library to visualize exposeure images. This tutorial demonstrates a few of the interactive features of the [Bokeh](https://bokeh.pydata.org/en/latest/), [HoloViews](http://holoviews.org/), and [Datashader](http://datashader.org/) plotting packages in the notebook environment. These packages are part of the [PyViz](http://pyviz.org/) set of python tools intended for visualization use cases in a web browser, and can be used to create quite sophisticated dashboard-like interactive displays and widgets. The goal of this notebook is to provide an introduction and starting point from which to create more advanced, custom interactive visualizations. \n",
    "\n",
    "#### 1.2 Learning Objectives\n",
    "After working through and studying this notebook you should be able to:\n",
    "   1. Use `holoviews` to visualize and interact with an exposure image. \n",
    "   1. Use `bokeh` to create interactive figures with brushing and linking between multiple plots\n",
    "   2. Use `holoviews` and `datashader` to create two-dimensional histograms with dynamic binning to efficiently explore large datasets   \n",
    "\n",
    "#### 1.3 Logistics\n",
    "This notebook is intended to be runnable on `data.lsst.cloud`. Note that occasionally the notebook may seem to stall, or the interactive features may seem disabled. If this happens, usually a restart of the kernel fixes the issue. You might also need to log out of the RSP and start a \"large\" instance of the JupyterLab environment. In some examples shown in this notebook, the order in which the cells are run is important for understanding the interactive features, so you may want to re-run the set of cells in a given section if you encounter unexpected behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What versions of bokeh and holoviews nd datashader are we working with?\n",
    "# This is important when referring to online documentation as\n",
    "# APIs can change between versions.\n",
    "print(\"Bokeh version: \" + bokeh.__version__)\n",
    "print(\"Holoviews version: \" + hv.__version__)\n",
    "print(\"Datashader version: \" + dsh.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exposure Image Visualization\n",
    "\n",
    "In this example we demonstrate image visualization at the pixel level with datashader.\n",
    "\n",
    "#### 3.1 Finding and retrieving an image with the `butler`\n",
    "For DP0.1, images can only be accessed via the `butler` (<a href=\"https://pipelines.lsst.io/modules/lsst.daf.butler/index.html\">documentation</a>), an LSST Science Pipelines software package that allows you to fetch the LSST data you want without you having to know its location or format. For more details on how to use the Butler, see tutorial 04_Intro_to_Butler. \n",
    "\n",
    "We will retrieve a deep r-band coadd image from a dataset, specifying a tract and patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Butler, which provides programmatic access to LSST data products.\n",
    "from lsst.daf.butler import Butler\n",
    "\n",
    "repo = 's3://butler-us-central1-dp01'\n",
    "collection = '2.2i/runs/DP0.1'\n",
    "butler = Butler(repo, collections=collection)\n",
    "\n",
    "dataId = {'tract': 4226, 'patch': 17, 'band': 'r'}\n",
    "\n",
    "# Retrieve a deep coadded calibrated exposure using the `butler` instance\n",
    "image = butler.get('deepCoadd', **dataId)\n",
    "assert image is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size = 200\n",
    "\n",
    "# Use an actual sensor image\n",
    "bounds_img = (0, 0, image.getDimensions()[0], image.getDimensions()[1])\n",
    "img = hv.Image(np.log10(image.image.array),\n",
    "               bounds=bounds_img).options(colorbar=True,\n",
    "                                          cmap=bokeh.palettes.Viridis256)\n",
    "\n",
    "boundsxy = (0, 0, 0, 0)\n",
    "box = streams.BoundsXY(source=img, bounds=boundsxy)\n",
    "bounds = hv.DynamicMap(lambda bounds: hv.Bounds(bounds), streams=[box])\n",
    "\n",
    "rasterize(img) * bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the histograms, it is possible to use interactive callback features on the image plots, such as the selection box. Use the box select tool on the image above and the execute the cell below to get the box boundary coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's another version of the image with a tap stream instead of box select. Click on the image to place an 'X' marker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=200\n",
    "%%opts Points (color='white' marker='x' size=20)\n",
    "\n",
    "posxy = hv.streams.Tap(source=img, x=0.5 * image.getDimensions()[0],\n",
    "                       y=0.5 * image.getDimensions()[1])\n",
    "marker = hv.DynamicMap(lambda x, y: hv.Points([(x, y)]), streams=[posxy])\n",
    "\n",
    "rasterize(img) * marker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'X' marks the spot! What's the value at that location? Execute the next cell to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The value at position (%.3f, %.3f) is %.3f' %\n",
    "      (posxy.x, posxy.y, image.image.array[-int(posxy.y), int(posxy.x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0  DP0.1 catalog data sample\n",
    "The data in the following example we will query the catalogs usig the TAP service to obtain a sample of data. For more details about using the TAP service and ADQL queries, please refer to tutorial 02_Intermediate_TAP_Query. We will use the same query as in thee "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Create the Rubin TAP Service client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rubin_jupyter_utils.lab.notebook import get_tap_service, retrieve_query\n",
    "service = get_tap_service()\n",
    "assert service is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Query the DP0.1 catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a reference position on the sky and cone radius in arcseconds\n",
    "# Coordinates obtained to optimize result set size \n",
    "c1 = SkyCoord(ra=59.7955707*u.degree, dec=-29.91176471*u.degree, frame='icrs')\n",
    "radius = 15.882353 * u.arcmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the corner coordinates of the polygon\n",
    "ra1 = bounds.getLon().getA()\n",
    "ra2 = bounds.getLon().getB()\n",
    "dec1 = bounds.getLat().getA()\n",
    "dec2 = bounds.getLat().getB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT COUNT(*) FROM dp01_dc2_catalogs.object \n",
    "WHERE CONTAINS(POINT('ICRS', ra, dec), \n",
    "               POLYGON('ICRS',59.48893247541351, -30.176108281372347, 60.10220892152004, -30.176108281372347, \n",
    "                       60.10220892152004, -29.647064552820886, 59.48893247541351, -29.647064552820886))=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT obj.objectId, obj.ra, obj.dec, obj.mag_g, obj.mag_r, \" \\\n",
    "        \"obj.mag_i, obj.mag_g_cModel, obj.mag_r_cModel, obj.mag_i_cModel,\" \\\n",
    "        \"obj.psFlux_g, obj.psFlux_r, obj.psFlux_i, obj.cModelFlux_g, \" \\\n",
    "        \"obj.cModelFlux_r, obj.cModelFlux_i, obj.tract, obj.patch, \" \\\n",
    "        \"obj.extendedness, obj.good, obj.clean, \" \\\n",
    "        \"truth.mag_r as truth_mag_r, truth.match_objectId, \"\\\n",
    "        \"truth.flux_g, truth.flux_r, truth.flux_i, truth.truth_type, \" \\\n",
    "        \"truth.match_sep, truth.is_variable \" \\\n",
    "        \"FROM dp01_dc2_catalogs.object as obj \" \\\n",
    "        \"JOIN dp01_dc2_catalogs.truth_match as truth \" \\\n",
    "        \"ON truth.match_objectId = obj.objectId \" \\\n",
    "        \"WHERE CONTAINS(POINT('ICRS', obj.ra, obj.dec),\"\\\n",
    "        \"CIRCLE('ICRS', \" + str(c1.ra.value) + \", \" + str(c1.dec.value) + \", \" \\\n",
    "        + str(radius.to(u.deg).value) + \" )) = 1 \" \\\n",
    "        \"AND truth.match_objectid >= 0 \"\\\n",
    "        \"AND truth.is_good_match = 1\"\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT obj.objectId, obj.ra, obj.dec, obj.mag_g, obj.mag_r, \" \\\n",
    "        \"obj.mag_i, obj.mag_g_cModel, obj.mag_r_cModel, obj.mag_i_cModel,\" \\\n",
    "        \"obj.psFlux_g, obj.psFlux_r, obj.psFlux_i, obj.cModelFlux_g, \" \\\n",
    "        \"obj.cModelFlux_r, obj.cModelFlux_i, obj.tract, obj.patch, \" \\\n",
    "        \"obj.extendedness, obj.good, obj.clean, \" \\\n",
    "        \"truth.mag_r as truth_mag_r, truth.match_objectId, \"\\\n",
    "        \"truth.flux_g, truth.flux_r, truth.flux_i, truth.truth_type, \" \\\n",
    "        \"truth.match_sep, truth.is_variable \" \\\n",
    "        \"FROM dp01_dc2_catalogs.object as obj \" \\\n",
    "        \"JOIN dp01_dc2_catalogs.truth_match as truth \" \\\n",
    "        \"ON truth.match_objectId = obj.objectId \" \\\n",
    "        \"WHERE CONTAINS(POINT('ICRS', obj.ra, obj.dec),\"\\\n",
    "        \"CIRCLE('ICRS', \" \\\n",
    "        + str(c1.ra.value) + \", \" + str(c1.dec.value) + \", \" \\\n",
    "        + str(radius.to(u.deg).value) + \" )) = 1 \" \\\n",
    "        \"AND truth.match_objectid >= 0 \"\\\n",
    "        \"AND truth.is_good_match = 1\"\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT obj.objectId, obj.ra, obj.dec, obj.mag_g, obj.mag_r, \" \\\n",
    "        \"obj.mag_i, obj.mag_g_cModel, obj.mag_r_cModel, obj.mag_i_cModel,\" \\\n",
    "        \"obj.psFlux_g, obj.psFlux_r, obj.psFlux_i, obj.cModelFlux_g, \" \\\n",
    "        \"obj.cModelFlux_r, obj.cModelFlux_i, obj.tract, obj.patch, \" \\\n",
    "        \"obj.extendedness, obj.good, obj.clean, \" \\\n",
    "        \"truth.mag_r as truth_mag_r, truth.match_objectId, \"\\\n",
    "        \"truth.flux_g, truth.flux_r, truth.flux_i, truth.truth_type, \" \\\n",
    "        \"truth.match_sep, truth.is_variable \" \\\n",
    "        \"FROM dp01_dc2_catalogs.object as obj \" \\\n",
    "        \"JOIN dp01_dc2_catalogs.truth_match as truth \" \\\n",
    "        \"ON truth.match_objectId = obj.objectId \" \\\n",
    "        \"WHERE CONTAINS(POINT('ICRS', ra, dec),POLYGON('ICRS', 59.53086482, -29.64705882, 60.06027658, -29.64705882, \"\\\n",
    "        \"59.53086482, -30.17647059, 60.06027658, -30.17647059))=1\"\\\n",
    "        \"AND truth.match_objectid >= 0 AND truth.is_good_match = 1\"\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT obj.objectId, obj.ra, obj.dec, obj.mag_g, obj.mag_r, obj.mag_i, obj.mag_g_cModel, obj.mag_r_cModel, \n",
    "obj.mag_i_cModel,obj.psFlux_g, obj.psFlux_r, obj.psFlux_i, obj.cModelFlux_g, obj.cModelFlux_r, obj.cModelFlux_i, \n",
    "obj.tract, obj.patch, obj.extendedness, obj.good, obj.clean, truth.mag_r as truth_mag_r, truth.match_objectId, \n",
    "truth.flux_g, truth.flux_r, truth.flux_i, truth.truth_type, truth.match_sep, truth.is_variable \n",
    "FROM dp01_dc2_catalogs.object as obj JOIN dp01_dc2_catalogs.truth_match as truth \n",
    "ON truth.match_objectId = obj.objectId \n",
    "WHERE CONTAINS(POINT('ICRS', ra, dec),POLYGON('ICRS', 59.53086482, -29.64705882, 60.06027658, -29.64705882, 59.53086482, -30.17647059, 60.06027658, -30.17647059))=1\n",
    "AND truth.match_objectid >= 0 AND truth.is_good_match = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Execute the query and convert the results to a pandas dataframe\n",
    "data = service.search(query).to_table().to_pandas()\n",
    "#assert len(data) == 14424\n",
    "assert len(data) == 102096"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Brushing and linking between scatter plots with Bokeh\n",
    "\n",
    "First, an example with brushing and linking between two panels showing different repsentations of the same dataset. \n",
    "A selection applied to either panel will highlight the selected points in the other panel.\n",
    "\n",
    "Based on http://bokeh.pydata.org/en/latest/docs/user_guide/interaction/linking.html#linked-brushing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column data source for the plots to share\n",
    "col_data = dict(x0=data['ra'] - c1.ra.value,\n",
    "                y0=data['dec'] - c1.dec.value,\n",
    "                x1=data['mag_g_cModel'] - data['mag_r_cModel'],\n",
    "                y1=data['mag_g_cModel'],\n",
    "                ra=data['ra'],\n",
    "                dec=data['dec'])\n",
    "source = ColumnDataSource(data=col_data)\n",
    "\n",
    "# Additional data can be added to the CDS after creation\n",
    "source.data['objectId'] = data['objectId']\n",
    "source.data['rmi'] = data['mag_r_cModel']-data['mag_i_cModel']\n",
    "source.data['gmr'] = data['mag_g_cModel']-data['mag_r_cModel']\n",
    "source.data['mag_r_cModel'] = data['mag_r_cModel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom hover tool on both panels\n",
    "hover_left = HoverTool(tooltips=[(\"(RA,DEC)\", \"(@ra, @dec)\"),\n",
    "                                 (\"(g-r,g)\", \"(@x1, @y1)\"),\n",
    "                                 (\"ObjectId\", \"@objectId\")])\n",
    "hover_right = HoverTool(tooltips=[(\"(RA,DEC)\", \"(@ra, @dec)\"),\n",
    "                                  (\"(g-r,g)\", \"(@x1, @y1)\"),\n",
    "                                  (\"ObjectId\", \"@objectId\")])\n",
    "TOOLS = \"box_zoom,box_select,lasso_select,reset,help\"\n",
    "TOOLS_LEFT = [hover_left, TOOLS]\n",
    "TOOLS_RIGHT = [hover_right, TOOLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat views based on the truth type\n",
    "# We will convert the truth_type integer to a more descriptive string\n",
    "object_map = {1: 'galaxy', 2: 'star', 3: 'SNe'}\n",
    "source.data['truth_type'] = data['truth_type'].map(object_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new plot and add a renderer\n",
    "left = figure(tools=TOOLS_LEFT, plot_width=400, plot_height=400,\n",
    "              output_backend=\"webgl\",\n",
    "              title='Spatial: Centered on (RA, Dec) = (%.2f, %.2f)' %\n",
    "              (c1.ra.value, c1.dec.value))\n",
    "left.circle('x0', 'y0', hover_color='firebrick', source=source,\n",
    "            selection_fill_color='steelblue',\n",
    "            selection_line_color='steelblue',\n",
    "            nonselection_fill_color='silver',\n",
    "            nonselection_line_color='silver')\n",
    "left.x_range = Range1d(0.4, -0.4)\n",
    "left.y_range = Range1d(-0.4, 0.4)\n",
    "left.xaxis.axis_label = 'Delta RA'\n",
    "left.yaxis.axis_label = 'Delta DEC'\n",
    "\n",
    "# create another new plot and add a renderer\n",
    "right = figure(tools=TOOLS_RIGHT, plot_width=400,\n",
    "               plot_height=400, output_backend=\"webgl\",\n",
    "               title='CMD')\n",
    "right.circle('x1', 'y1', hover_color='firebrick', source=source,\n",
    "             selection_fill_color='steelblue',\n",
    "             selection_line_color='steelblue',\n",
    "             nonselection_fill_color='silver',\n",
    "             nonselection_line_color='silver')\n",
    "right.x_range = Range1d(-0.5, 2.5)\n",
    "right.y_range = Range1d(26., 16.)\n",
    "right.xaxis.axis_label = 'g - r'\n",
    "right.yaxis.axis_label = 'g'\n",
    "\n",
    "p = gridplot([[left, right]])\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the hover tool to see information about individual datapoints (e.g., the objectd). This information should appear automatically as you hover the mouse over the datapoints. Notice the data points highlighted in red on one panel with the hover tool are also highlighted on the other panel.\n",
    "\n",
    "Next, click on the selection box icon (with a \"+\" sign) or the selection lasso icon found in the upper right corner of the figure. Use the selection box and selection lasso to make various selections in either panel by clicking and dragging on either panel. The selected data points will be displayed in the other panel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 Further analysis with Holoviews Linked Streams\n",
    "\n",
    "If we want to do subsequent calculations with the set of selected points, we can use HoloViews linked streams for custom interactivity. The following visualization is a modification of this example. As for the example above, use the selection box and selection lasso to datapoints on the left panel. The selected points should appear in the right panel. Finally, notice that as you change the selection on the left panel, the mean x- and y-values for selected datapoints are shown in the title of right panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Points [tools=['box_select', 'lasso_select']]\n",
    "%%output size=150\n",
    "\n",
    "# Declare some points\n",
    "points = hv.Points((data['ra'] - c1.ra.value, data['dec'] - c1.dec.value))\n",
    "\n",
    "# Declare points as source of selection stream\n",
    "selection = streams.Selection1D(source=points)\n",
    "\n",
    "\n",
    "# Function that uses the selection indices to slice points and compute stats\n",
    "def selected_info(index):\n",
    "    selected = points.iloc[index]\n",
    "    if index:\n",
    "        label = 'Mean x, y: %.3f, %.3f' % tuple(selected.array().mean(axis=0))\n",
    "    else:\n",
    "        label = 'No selection'\n",
    "    return selected.relabel(label).options(color='red')\n",
    "\n",
    "\n",
    "# Combine points and DynamicMap\n",
    "# Notice the syntax used here: the \"+\" sign makes side-by-side panels\n",
    "points + hv.DynamicMap(selected_info, streams=[selection])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we access the indices of the selected datapoints. We could use these indices to select a subset of full sample for further examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(selection.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0  Visualizing Larger Datasets with Datashader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interactive features of Bokeh work well with datasets up to a few tens of thousands of data points. To efficiently explore larger datasets, we'd like to use another visualization model that offers better scalability, namely Datashader.\n",
    "\n",
    "In the examples below, notice that as one zooms in on the datashaded two-dimensional histograms, the bin sizes are dynamically adjusted to show finer or coarser granularity in the distribution. This allows one to interactively explore large datasets without having to manually adjust the bin sizes while panning and zooming. Zoom in all the way and you can see individual points (i.e., bins contain either zero or one count). If you zoom in far enough, the individual points are represented by extremely small pixels in datashader that are difficult to see. A solution is to dynspread instead of datashade, which will preserve a finite size of the plotted points.\n",
    "\n",
    "The next cell also uses the concept of linked Streams in HoloViews for custom interactivity, in this case to create a selection box. We'll use that selection box tool in the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Color-color plot \n",
    "\n",
    "Here we plot a color-colour diagram of the c-model magnitudes obtained fron the query in 3.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create color-color plot using bokeh\n",
    "plot_options = {'plot_height': 300, 'plot_width': 800,\n",
    "                'tools': ['hover', 'box_select', 'reset', 'help']}\n",
    "\n",
    "hover = HoverTool(tooltips=[(\"objectId\", \"@objectId\"),\n",
    "                            (\"(RA,DEC)\", \"(@ra, @dec)\"),\n",
    "                            (\"(g-r,r-i)\", \"(@gmr, @rmi)\"),\n",
    "                            (\"type\", \"@truth_type\")])\n",
    "\n",
    "p = figure(title=\"Colour-Colour Diagram (cModel magnitudes)\",\n",
    "           x_axis_label=\"g-r\", y_axis_label=\"r-i\",\n",
    "           x_range=(-2.0, 3.0), y_range=(-2.0, 3.0),\n",
    "           **plot_options)\n",
    "p.circle(x='gmr', y='rmi', source=source,\n",
    "         size=3, alpha=0.3,\n",
    "         hover_color='firebrick',\n",
    "         legend_field=\"truth_type\",\n",
    "         color=factor_cmap('truth_type', 'Category10_3',\n",
    "                           ['galaxy', 'star', 'SNe']))\n",
    "p.add_tools(hover)\n",
    "\n",
    "# Change to gridplot with stars to the right \n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that even with a medium sized dataset of ~14K points, this plot suffers from overplotting.  A classic strategy is to specify transparency of the glyphs so we can better see sparse and dense areas. In the plot above we have `alpha=0.3`. This helps but washes out the detail in the sparser regions. An additional problem is that we cannot add too many glyphs to any plot. \n",
    "\n",
    "Holoviews + Datashader allows us to plot millions to billions of points this to produce much more informative plots. DataShader rasterizes or aggregates datasets into regular grids that can then be further analysed or viewed as images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Points [tools=['box_select']]\n",
    "\n",
    "# Create a holoviews object to hold and plot data\n",
    "points = hv.Points((source.to_df()['gmr'], source.to_df()['rmi']))\n",
    "\n",
    "# Create the linked streams instance\n",
    "boundsxy = (0, 0, 0, 0)\n",
    "box = streams.BoundsXY(source=points, bounds=boundsxy)\n",
    "bounds = hv.DynamicMap(lambda bounds: hv.Bounds(bounds), streams=[box])\n",
    "\n",
    "# Apply the datashader\n",
    "dynspread(datashade(points, cmap=\"Viridis\").opts(\n",
    "    width=800, height=300,\n",
    "    padding=0.05, show_grid=True,\n",
    "    xlim=(-2.0, 3.0), ylim=(-2.0, 3.0),\n",
    "    xlabel=\"g-r\", ylabel=\"r-i\")) * bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `datashade` plot of the same color-color diagram as above shows muchj more detail.  Select the `wheel zoom` and adjust the image as you interact with the plot. Note how the shades of color of the data points change according to the local density."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we add callback functionality to the plot above and retrieve the indices of the selected points. First, use the box selection tool to create a selection box for the two-dimensional histogram above. Then run the cell below to count the number of datapoints within the selection region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = (points.data.x > box.bounds[0]) \\\n",
    "    & (points.data.y > box.bounds[1]) \\\n",
    "    & (points.data.x < box.bounds[2]) \\\n",
    "    & (points.data.y < box.bounds[3])\n",
    "print('The selection box contains %i datapoints'%(np.sum(selection)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot a spatial distribution on the sky of all the data and link it to a two-dimansional histogram of the data in the box selection. Try changing the box selection and watch as the historgram is recomputed and displayed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a holoviews dataset instance. \n",
    "# Here we label some of the columns.\n",
    "kdims = [('ra', 'RA(deg)'), ('dec', 'Dec(deg)')]\n",
    "vdims = [('mag_r_cModel', 'r(mag)')]\n",
    "ds = hv.Dataset(source.to_df(), kdims, vdims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = hv.Points(ds)\n",
    "boundsxy = (np.min(ds.data['ra']), np.min(ds.data['dec']),\n",
    "            np.max(ds.data['ra']), np.max(ds.data['dec']))\n",
    "box = streams.BoundsXY(source=points, bounds=boundsxy)\n",
    "box_plot = hv.DynamicMap(lambda bounds: hv.Bounds(bounds), streams=[box])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback functionality to update the linked histogram\n",
    "def log_inf(x):\n",
    "    return np.log(x) if x > 0 else 0\n",
    "\n",
    "\n",
    "def update_histogram(bounds=bounds):\n",
    "    selection = (ds.data['ra'] > bounds[0]) & \\\n",
    "                (ds.data['dec'] > bounds[1]) & \\\n",
    "                (ds.data['ra'] < bounds[2]) & \\\n",
    "                (ds.data['dec'] < bounds[3])\n",
    "\n",
    "    selected_mag = ds.data.loc[selection]['mag_r_cModel']\n",
    "    frequencies, edges = np.histogram(selected_mag)\n",
    "    hist = hv.Histogram((list(map(log_inf, frequencies)), edges))\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=150\n",
    "dmap = hv.DynamicMap(update_histogram, streams=[box])\n",
    "datashade(points,\n",
    "          cmap=process_cmap(\"Viridis\", provider=\"bokeh\")) * box_plot + dmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Documentation\n",
    "\n",
    "If you'd like some more information on `bokeh`, `holoviews` and `datashader`, please have a look at the following websites:\n",
    "\n",
    "* [Bokeh website](https://bokeh.org/)  \n",
    "* [Holovioews website](http://holoviews.org/index.html)  \n",
    "* [Datashader website](https://datashader.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
