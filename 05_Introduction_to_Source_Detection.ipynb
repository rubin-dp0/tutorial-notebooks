{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749b0ddf",
   "metadata": {},
   "source": [
    "<img align=\"left\" src = https://project.lsst.org/sites/default/files/Rubin-O-Logo_0.png width=250 style=\"padding: 10px\"> \n",
    "<b>Introduction to Source Detection</b> <br>\n",
    "Contact authors: Douglas Tucker, Alex Drlica-Wagner<br>\n",
    "Last verified to run: 2022-09-29 <br>\n",
    "LSST Science Piplines version: Weekly 2022_40 <br>\n",
    "Container Size: medium <br>\n",
    "Targeted learning level: Intermediate <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da1a210-d858-42fe-8591-570965b8be1a",
   "metadata": {},
   "source": [
    "**Description:** Access, display, and manipulate images; detect, deblend, and measure sources; and extract, plot, and use object footprints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a0baf5-51ad-40ec-8991-060a7b27c289",
   "metadata": {},
   "source": [
    "**Skills:** Run source detection, deblending and measurement. Use source \"footprints\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393da88f-7978-4920-aa4a-a9830df6eed9",
   "metadata": {},
   "source": [
    "**LSST Data Products:** Butler calexp images and mask planes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c67fab9-136a-4adc-bb42-142b91ab69dd",
   "metadata": {},
   "source": [
    "**Packages:** lsst.pipe.tasks.characterizeImage, lsst.meas.algorithms.detection, lsst.meas.deblender, lsst.meas.base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f72b27f",
   "metadata": {},
   "source": [
    "**Credit:**\n",
    "Originally developed by Alex Drlica-Wagner and Imran Hasan in the context of the LSST Stack Club."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e91cbf-ab7f-4e26-9276-b00299d6065e",
   "metadata": {},
   "source": [
    "**Get Support:**\n",
    "Find DP0-related documentation and resources at <a href=\"https://dp0-2.lsst.io\">dp0-2.lsst.io</a>. Questions are welcome as new topics in the <a href=\"https://community.lsst.org/c/support/dp0\">Support - Data Preview 0 Category</a> of the Rubin Community Forum. Rubin staff will respond to all questions posted there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc73be0",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This notebook provides a brief introduction to running the LSST Science Pipelines source detection, measurement, and deblending algorithms. It does not go into depth about optimizing detection, measurement, or deblending parameters for different types of sources. \n",
    "\n",
    "Some source detection and measurement details come from Robert Lupton's [Tune Detection.ipynb](https://github.com/RobertLuptonTheGood/notebooks/blob/master/Demos/Tune%20Detection.ipynb) and [Kron.ipynb](https://github.com/RobertLuptonTheGood/notebooks/blob/master/Demos/Kron.ipynb).\n",
    "Interaction with `lsst.afw.display` was also improved by studying Michael Wood-Vasey's [DC2_Postage Stamps.ipynb](https://github.com/LSSTDESC/DC2-analysis/blob/master/tutorials/dm_butler_postage_stamps.ipynb).\n",
    "More information on footprints can be found on the Stack Club notebook by Imran Hasan [here](https://github.com/LSSTScienceCollaborations/StackClub/blob/master/SourceDetection/Footprints.ipynb).\n",
    "\n",
    "After working through this notebook you should be able to run the `lsst.meas.algorithm` source detection, deblending, and measurement tasks; plot the resulting source catalogs on an image; and examine the `footprint` of the detected sources.  Other techniques that are demonstrated (but not emphasized) include the use of the `butler` to access a specific `calexp`, the creation of an image cutout; and the and use of `lsst.afw.display` to plot the image cutout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc36f107",
   "metadata": {},
   "source": [
    "### 1.1. Package Imports\n",
    "\n",
    "The [`matplotlib`](https://matplotlib.org/) library is a widely used Python plot library. \n",
    "\n",
    "We load the `lsst.afw.display` library to gain access to the image visualization routines we'd like to use, and the `lsst.daf.butler` library, which is used to access data products.  The `lsst.afw.image` and `lsst.afw.table` libraries provide handlers, respectively for the image and table outputs of the LSST Science Pipelines.  The `lsst.afw.geom` provide sky- and LSST-specific geometric routines. \n",
    "\n",
    "As we will see later, the `lsst.pipe.tasks.characterizeImage` library is used for characterizing properties of a given image (like PSF), the `lsst.meas.algorithms.detection` library provides methods for detecting sources within an image, the `lsst.meas.deblender` library gives methods for deblending sources into component parts (\"children\"), and the `lsst.meas.base` includes methods for measuring the properties of sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc506441-c5c1-4101-9090-3f2c59a04a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General python packages\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# LSST Science Pipeline packages (see pipelines.lsst.io)\n",
    "import lsst.daf.base as dafBase\n",
    "from lsst.daf.butler import Butler\n",
    "import lsst.afw.image as afwImage\n",
    "import lsst.afw.display as afwDisplay\n",
    "import lsst.afw.table as afwTable\n",
    "import lsst.geom as geom\n",
    "\n",
    "# Pipeline tasks\n",
    "from lsst.pipe.tasks.characterizeImage import CharacterizeImageTask\n",
    "from lsst.meas.algorithms.detection import SourceDetectionTask\n",
    "from lsst.meas.deblender import SourceDeblendTask\n",
    "from lsst.meas.base import SingleFrameMeasurementTask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce4e490-ad26-4738-b555-920096deec40",
   "metadata": {},
   "source": [
    "### 1.2. Define functions and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6e035b-e492-42ed-b57a-ddbcff9a3220",
   "metadata": {},
   "source": [
    "Set the matplotlib plot color table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36096062-7851-4099-bd5a-ad35efacb434",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('tableau-colorblind10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c0591c-a29a-4fab-b3f1-b09340eca85a",
   "metadata": {},
   "source": [
    "Let us also set `lsst.afw.display` to use the `matplotlib` backend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03be07b0-1853-4545-8312-d0a9b5d9ea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "afwDisplay.setDefaultBackend('matplotlib')\n",
    "plt.rcParams['figure.figsize'] = (8.0, 8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26304af-d7a5-4625-8adf-294612a7b654",
   "metadata": {},
   "source": [
    "## 2. Data Access\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5054c016-b2dc-491d-bac4-0a0ef1c6c87e",
   "metadata": {},
   "source": [
    "### 2.1. Access the `calexp` Data\n",
    "\n",
    "Here we use the `butler` to access a `calexp` from the DP0.2 dataset. More information on the `butler` and `calexp`, \n",
    "and how to determine the `dataId` (e.g., the visit and detector numbers) are available in other tutorials. \n",
    "We assume that this information is known."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb1ff23-a9c7-41cd-bc97-dd7e6c9be007",
   "metadata": {},
   "source": [
    "First, let us define the configuration and collection and instantiate an instance of the butler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc5b27f-c583-4480-8f18-6e4937cd289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DP0.2, we want the following configuration and collection:\n",
    "config = \"dp02\"\n",
    "collection = '2.2i/runs/DP0.2'\n",
    "\n",
    "butler = Butler(config=config, collections=collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba4499-ec3f-403c-9bfc-7f95b9c0d147",
   "metadata": {},
   "source": [
    "Let us look at the `calexp` data for `detector` 75 in `visit` 512055."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee02e9-9951-44af-a3d9-8a32bf61b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataId using just visit and detector\n",
    "dataId = {'visit': 512055, 'detector': 75}\n",
    "\n",
    "# Use the butler to get the calexp\n",
    "calexp = butler.get('calexp', **dataId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a164425-c575-4b86-9fa1-ad6095c67dc3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "As described in other tutorials, the `calexp` object possess more than just the raw pixel data of the image. It also contains a `mask`, which stores information about various pixels in a bit mask.\n",
    "\n",
    "Here are some optional commands to explore the calexp. Uncomment one of the code lines to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8826d069-1606-4710-8933-a543f9179a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to investigate the contents of the masked image:\n",
    "# calexp.maskedImage\n",
    "\n",
    "# If you just want one of the three components:\n",
    "# calexp.maskedImage.image\n",
    "# calexp.maskedImage.mask\n",
    "# calexp.maskedImage.variance\n",
    "\n",
    "# These also work:\n",
    "# calexp.image\n",
    "# calexp.mask\n",
    "# calexp.variance\n",
    "\n",
    "# The calexp also contains the PSF, the WCS, and the photometric calibration\n",
    "# calexp.getPsf()\n",
    "# calexp.getWcs()\n",
    "# calexp.getPhotoCalib()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8634d4c4-f318-434f-b77c-e8ddef26f156",
   "metadata": {},
   "source": [
    "Since we are interested in performing our own source detection and measurement, we choose to clear the existing `DETECTED` mask plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344af33c-1c87-4a2c-9630-34522bce34f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unset the `DETECTED` bits of the mask plane\n",
    "calexp.mask.removeAndClearMaskPlane('DETECTED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bb16af-003b-43d1-bafb-38dedb54f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the calexp we just retrieved\n",
    "plt.figure()\n",
    "afw_display = afwDisplay.Display()\n",
    "afw_display.scale('asinh', 'zscale')\n",
    "afw_display.mtv(calexp.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d581c53a-714f-4b54-a4c1-63bfc9efebb9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.2. Add the Subtracted Sky Background Back into the Image\n",
    "\n",
    "Here we retrieve the subtracted background for the same dataId and add it back into the image. This section is optional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e165a470-9ac4-445f-a676-bfdff0f92bd1",
   "metadata": {},
   "source": [
    "First, we obtain the `calexpBackground` object for this `dataId`.  We will again use the `butler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96653ac-20ec-4343-a195-63b331cc6713",
   "metadata": {},
   "outputs": [],
   "source": [
    "bkgd = butler.get('calexpBackground', **dataId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb47b27-e037-49e9-968e-6f5d52e3c6e4",
   "metadata": {},
   "source": [
    "Now, let us display the background we obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bb7ded-9fa6-4762-825a-81fb16edab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "afw_display = afwDisplay.Display()\n",
    "afw_display.scale('linear', 'zscale')\n",
    "afw_display.mtv(bkgd.getImage())\n",
    "plt.title(\"Local Polynomial Background\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca7a86-c50d-407a-bf12-f6e18bfb0be4",
   "metadata": {},
   "source": [
    "Next, we add the background into the `calexp`, and re-display the `calexp`. Note the scale in the sidebar now goes up to thousands of counts instead of hundreds of counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78406756-4cdb-4782-9778-52c2e5be17f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: executing this cell multiple times will add the background\n",
    "#  multiple times\n",
    "calexp.maskedImage += bkgd.getImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0490c4a-db2e-4efb-a81c-b4adec0fda75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "afw_display = afwDisplay.Display()\n",
    "afw_display.scale('asinh', 'zscale')\n",
    "afw_display.mtv(calexp.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7d475f-df1f-476b-89cf-9f912833c31a",
   "metadata": {},
   "source": [
    "## 3. Source Detection, Deblending, and Measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa35bd1-6e37-4aa9-b78d-87f958dee916",
   "metadata": {},
   "source": [
    "We now want to run the LSST Science Pipelines' source detection, deblending, and measurement tasks. While we run all three tasks, this notebook is mostly focused on the detection of sources.\n",
    "\n",
    "Recall that these tasks were imported up at the top of this notebook, from `lsst.pipe` and `lsst.meas`. More information can be found at [pipelines.lsst.io](https://pipelines.lsst.io/) (the search bar at the top left of that page is a very handy way to find documentation for a specific task).\n",
    "\n",
    "We start by creating a minimal schema for the source table. The schema describes the output properties that will be measured for each source. This schema will be passed to all of the tasks, as we call each in turn, and each task will add columns to this schema as it measures sources in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa6787b-aaa5-44a3-ba6c-db3ad87a7bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a basic schema to use with these tasks\n",
    "schema = afwTable.SourceTable.makeMinimalSchema()\n",
    "print(schema)\n",
    "\n",
    "# Create a container which will be used to record metadata\n",
    "#  about algorithm execution\n",
    "algMetadata = dafBase.PropertyList()\n",
    "print('algMetadata: ')\n",
    "algMetadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf0992b-f964-40ff-8f65-1f1b1a6de733",
   "metadata": {},
   "source": [
    "### 3.1. Configuring Tasks\n",
    "\n",
    "Each task possesses an associated configuration class. The properties of these configuration classes can be determined from the classes themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8603996-260e-4dd9-88f5-b1c74d1ff3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to view help\n",
    "#  for the CharacterizeImageTask configuration\n",
    "# Replace 'CharacterizeImageTask' with a different\n",
    "#  task name to view additional help information\n",
    "\n",
    "# help(CharacterizeImageTask.ConfigClass())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddac4a8e-78d3-48c2-a6ea-3c05239c92b5",
   "metadata": {},
   "source": [
    "As a starting point, like the `schema` and `algMetadata` above, here we set some basic config parameters and instantiate the tasks to get you started. In this case, we configure several different tasks:\n",
    "\n",
    "* CharacterizeImageTask: Characterizes the image properties (e.g., PSF, etc.)\n",
    "* SourceDetectionTask: Detects sources\n",
    "* SourceDeblendTask: Deblend sources into constituent \"children\"\n",
    "* SingleFrameMeasurementTask: Measures source properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c434d66c-4ddc-42af-8b69-ee25a67a04ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterize the image properties\n",
    "config = CharacterizeImageTask.ConfigClass()\n",
    "config.psfIterations = 1\n",
    "charImageTask = CharacterizeImageTask(config=config)\n",
    "\n",
    "# Detect sources\n",
    "config = SourceDetectionTask.ConfigClass()\n",
    "# detection threshold in units of thresholdType\n",
    "config.thresholdValue = 10\n",
    "# units for thresholdValue\n",
    "config.thresholdType = \"stdev\"\n",
    "sourceDetectionTask = SourceDetectionTask(schema=schema, config=config)\n",
    "\n",
    "# Deblend sources\n",
    "sourceDeblendTask = SourceDeblendTask(schema=schema)\n",
    "\n",
    "# Measure source properties\n",
    "config = SingleFrameMeasurementTask.ConfigClass()\n",
    "sourceMeasurementTask = SingleFrameMeasurementTask(schema=schema,\n",
    "                                                   config=config,\n",
    "                                                   algMetadata=algMetadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a3f968-af7c-4f26-b1db-3f011ae87e2d",
   "metadata": {},
   "source": [
    "Note that if you want to change the value of a config parameter (e.g., `psfIterations`), do not change it in the already constructed task. Instead, change your config object and then construct a new characterize image task. Like so:\n",
    "> `config.psfIterations = 3` <br>\n",
    "> `charImageTask = CharacterizeImageTask(config=config)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119063c7-3185-489b-988f-36be2148d824",
   "metadata": {},
   "source": [
    "Like the configs, we can use `help` to explore each task and the methods used to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba8289-efe9-470c-91cf-38194f624557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(charImageTask)\n",
    "\n",
    "# Uncomment the following line, position your cursor after the period,\n",
    "#  and press tab to see a list of all methods. Then recomment the line\n",
    "#  because \"Task.\" is not executable and will cause an error.\n",
    "# charImageTask.\n",
    "\n",
    "# Use the help function on any of the methods to learn more:\n",
    "# help(charImageTask.writeSchemas)\n",
    "\n",
    "# E.g., find out what options there are for config.thresholdType\n",
    "# help(SourceDetectionTask.ConfigClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687db243-8ab9-428e-a7ac-fbbbd4c218d1",
   "metadata": {},
   "source": [
    "With the each of the tasks configured, we can now move on to running the source detection, deblending, and measurement. First we create `SourceTable` for holding the output of our source analysis. The columns and characteristics of this table are defined by the `schema` that we created in our configuration step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8f87bf-eb85-46df-a917-2bf735b42f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = afwTable.SourceTable.make(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d349fb9-c61b-465e-b381-bc2798c76acf",
   "metadata": {},
   "source": [
    "### 3.2. Image Characterization\n",
    "\n",
    "Next we characterize our image. This calculates various global properties of the image, such as the full-width half-max of its point spread function (PSF FWHM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375f681d-804f-494e-b073-f66c6d7f4c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image characterization (this cell may take a few seconds)\n",
    "result = charImageTask.run(calexp)\n",
    "\n",
    "# Define the pixel coordinates of a point of interest\n",
    "# (in this case, basically a random point within the image)\n",
    "x_target, y_target = 1700, 2100\n",
    "width, height = 400, 400\n",
    "xmin, ymin = x_target-width//2, y_target-height//2\n",
    "point = geom.Point2D(x_target, y_target)\n",
    "\n",
    "# Get the PSF at our point of interest\n",
    "psf = calexp.getPsf()\n",
    "sigma = psf.computeShape(point).getDeterminantRadius()\n",
    "pixelScale = calexp.getWcs().getPixelScale().asArcseconds()\n",
    "\n",
    "# The factor of 2.355 converts from std to fwhm\n",
    "print('psf fwhm = {:.2f} arcsec'.format(sigma*pixelScale*2.355))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d64ca72-ace2-4d30-a0fd-d0fdef5c93be",
   "metadata": {},
   "source": [
    "With the image characterized, we are now interested in running the source detection, deblending, and measurement tasks. Each of these tasks is called with the `run` method. The parameters of this method can be investigated using `help`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d7dc6-1869-424b-8196-fc620d47436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are specifically interested in the `SourceMeasurementTask`\n",
    "# help(sourceMeasurementTask.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566e107-559d-4eae-830d-e001e4fe42c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source detection (this cell may take a few seconds)\n",
    "result = sourceDetectionTask.run(tab, calexp)\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386d20f9-8234-4e0a-8bdf-c465fccb0b07",
   "metadata": {},
   "source": [
    "The source detection task returns an [`lsst.pipe.base.struct.Struct`](http://doxygen.lsst.codes/stack/doxygen/x_masterDoxyDoc/classlsst_1_1pipe_1_1base_1_1struct_1_1_struct.html). A `Struct` is just a generalized container for storing multiple output components and accessessing them as attributes. The content of this `Struct` can be investigated with the `getDict` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfc6fae-3ebb-4b96-8ca0-7f187d5c0807",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in result.getDict().items():\n",
    "    print(k, type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ab3e88-432a-4f0e-9168-0c72956e969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.numPosPeaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e9f774-001b-4558-9579-16723ab00e0d",
   "metadata": {},
   "source": [
    "When we use `config.thresholdValue = 10` we get about 940 positive peaks. If we rerun with `config.thresholdValue = 3` we would find about 5340 positive peaks.  (Exact numbers for this image depend on version of the DM Stack used and version the configuration files employed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444d2882-7758-4389-9d63-cda648e1920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = result.sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c4d28d-a76a-4438-a07d-d3d3614828ed",
   "metadata": {},
   "source": [
    "Most of the columns for sources will be NaN at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c278486f-c8f0-45f4-9c2f-1b7ce54975d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to see that most values are NaN\n",
    "# sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e071a046-bb3c-4bf3-a667-14f1bbbd3996",
   "metadata": {},
   "source": [
    "Note that if we desire we can save these processed sources to disk as FITS tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a04e1fc-418c-4195-992f-7809bcfc5223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources.writeFits(\"outputTable.fits\")\n",
    "# calexp.writeFits(\"example1-out.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc659715-c636-43d8-b727-54d09936276f",
   "metadata": {},
   "source": [
    "### 3.3. Deblend and Measure Sources\n",
    "\n",
    "Next we run the `SourceDeblendTask` and `SingleFrameMeasurementTask`. A deeper investigation of these tasks is beyond the scope of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4587f17-fef0-409d-8e68-e18a079ee94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source deblending\n",
    "sourceDeblendTask.run(calexp, sources)\n",
    "\n",
    "# Source measurement\n",
    "sourceMeasurementTask.run(measCat=sources, exposure=calexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e588432-ff0f-4fc7-bdcc-4d6cc47e26cd",
   "metadata": {},
   "source": [
    "To get a better look at the output sources, we need to make sure that the `SourceCatalog` is contiguous in memory. Converting to an `astropy` table provides a human-readable output format. A deeper dive into `SourceCatalog` is beyond the scope of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d32012d-8bbd-4962-85c7-402b948c495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The copy makes sure that the sources are sequential in memory\n",
    "sources = sources.copy(True)\n",
    "\n",
    "# Investigate the output source catalog\n",
    "sources.asAstropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5760a2d-2eaf-45ba-818f-c7d50fe7011d",
   "metadata": {},
   "source": [
    "### 3.4. Overplot Sources on Image\n",
    "\n",
    "We can now overplot our detected sources on the calexp or a cutout image using `afwDisplay`.\n",
    "\n",
    "Let's do this for a cutout image instead of the full calexp.  To generate a cutout image of the calexp, create a bounding box and passing it to the `Factory` method of our calexp (a `lsst.afw.image.Exposure` object). Below we explain the specific arguments that we are passing to `Factory`:\n",
    "```\n",
    "calexp : the ExposureF we are starting from\n",
    "bbox   : the bounding box of the cutout\n",
    "origin : the image pixel origin is local to the cutout array\n",
    "deep   : copy the data rather than passing by reference\n",
    "```\n",
    "\n",
    "<a id='display-error'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d901b23-faf3-4d35-aa51-6fff33d02780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a small region for a cutout\n",
    "bbox = geom.Box2I()\n",
    "bbox.include(geom.Point2I(xmin, ymin))\n",
    "bbox.include(geom.Point2I(xmin + width, ymin + height))\n",
    "\n",
    "# An alternative way to defined the same cutout region\n",
    "# bbox = geom.Box2I(geom.Point2I(xmin, ymin), geom.Extent2I(width, height))\n",
    "\n",
    "# Generate the cutout image\n",
    "cutout = calexp.Factory(calexp, bbox, origin=afwImage.LOCAL, deep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4304b9a2-13fa-4af3-862b-c90efe64e6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the cutout and sources with afw display\n",
    "image = cutout.image\n",
    "plt.figure()\n",
    "afw_display = afwDisplay.Display()\n",
    "afw_display.scale('asinh', 'zscale')\n",
    "afw_display.mtv(image)\n",
    "plt.gca().axis('off')\n",
    "\n",
    "# We use display buffering to avoid re-drawing the image\n",
    "#  after each source is plotted\n",
    "with afw_display.Buffering():\n",
    "    for s in sources:\n",
    "        afw_display.dot('+', s.getX(), s.getY(), ctype=afwDisplay.RED)\n",
    "        afw_display.dot('o', s.getX(), s.getY(), size=20, ctype='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0695c973-e7ce-4c51-9d0e-327a7b0a0847",
   "metadata": {},
   "source": [
    "## 4. Footprints\n",
    "\n",
    "Object footprints are an integral component of the high-level CCD processing tasks (e.g., detection, measurement, and deblending). To quote [Bosch et al. (2017)](https://arxiv.org/pdf/1705.06766.pdf), \n",
    "\n",
    "> Footprints record the exact above-threshold detection region on a CCD. These are similar to  SExtractor’s “segmentation map\", in that they identify which pixels belong to which detected objects\n",
    "\n",
    "This quote draws an analogy between footprints and segmentation maps, since they both identify pixels with values above some threshold. This is a useful similarity, since it gives us a place to start understanding the properties of footprints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d669722-007f-451b-9de7-679f9681e359",
   "metadata": {},
   "source": [
    "The result of the `SourceDetectionTask` stores the footprints associated to detected objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a5c82b-9c2b-4f5a-8d0b-0df92182d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the above-threshold footprints that were detected,\n",
    "#  and assign them to the variable `fps`\n",
    "fpset = result.positive\n",
    "fps = fpset.getFootprints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533489f-d53e-4a72-a4f3-6e0601a20d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get a rough view of the first source's footprint from its span\n",
    "fps[0].getSpans()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d27c87-6212-43e3-a965-aabcde5d9921",
   "metadata": {},
   "source": [
    "You can almost see the footprint by looking at the 1's and 0's here. Keep in mind that the first row of this array will be the *bottom* row of the image. Later, when we display the footprint, its general pattern will appear \"upside down\" compared to this pattern of 1s. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ba5221-a8c0-4e67-b803-ee7f09fe154e",
   "metadata": {},
   "source": [
    "### 4.1. Heavy Footprints\n",
    "\n",
    "At the moment, our footprints indicate which pixels they consist of, but not the values of those pixels from the image. To extract the actual values of the pixels that correspond to the ones in the footprint span, we need to convert our footprint into a `HeavyFootprint`. HeavyFootprints have all of the qualities of Footprints, but additionally 'know' about pixel level data from the image, variance, and mask planes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5859334b-b7b8-407c-bd77-f26b431aa9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we demonstrate that the footprint is NOT heavy\n",
    "fps[0].isHeavy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3026cdd5-66e7-4a17-95a1-375f8cb34da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we make all the footprints heavy at the same time\n",
    "#  by operating on the footprint set\n",
    "fpset.makeHeavy(calexp.getMaskedImage())\n",
    "\n",
    "# This means we have to redefine fps:\n",
    "hfps = fpset.getFootprints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69669f9-210c-476e-8ec2-baf9ef3ea3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of the arrays here will be flattend 1D arrays\n",
    "#  of pixels from the footprint.\n",
    "# Uncomment this line to print the array and see that\n",
    "#  now, it contains pixel values.\n",
    "\n",
    "# hfps[0].getImageArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5119ea4e-a0aa-470f-9dd7-350eb516d477",
   "metadata": {},
   "source": [
    "Now we can use the span set to reassemble the image array into the footprint. Above we saw that the image array is a 1D numpy array, but the footprint itself is 2 dimensional. Fortunately, the span set has an `unflatten` method that rearranges the image array into the proper 2 dimensional shape. If you want to change the colormap, see [matplotlib colormap options](https://matplotlib.org/stable/tutorials/colors/colormaps.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c81694-1701-4f34-b199-dec8808281fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(fps[0].getSpans().unflatten(hfps[0].getImageArray()),\n",
    "           cmap='bone', origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb82b3-8292-4873-9d56-0673b16644f3",
   "metadata": {},
   "source": [
    "The heavy footprint also comes with a 1d mask array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad83499-fbb1-446b-96e6-c91543837abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfps[0].getMaskArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c49846-d734-445c-895e-4e7700287eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "calexp.getMask().getMaskPlaneDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9730bce0-bfa6-4b57-b183-b7a21188290c",
   "metadata": {},
   "source": [
    "The values are the exponent of the bitmask. So pixels only marked detected will be 2^5 = 32. Pixels that are both on the edge of the original image and detected will be 2^5 + 2^4 = 48. We will visualize the mask plane values in a similar manner as before, except that we will be displaying the values of the mask array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b04e62-64da-4f15-afd6-4d162999d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "im = plt.imshow(fps[0].getSpans().unflatten(hfps[0].getMaskArray()),\n",
    "                origin='lower')\n",
    "\n",
    "# Create a new axis, \"cax\" on the right side of the image display.\n",
    "# The width of cax will be 5% of the axis \"ax\".\n",
    "# The padding between cax and ax will be 1% of the axis.\n",
    "ax = plt.gca()\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=\"1%\")\n",
    "plt.colorbar(im, cax=cax, ticks=[0, 32, 32+16])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
